--- title: Feelings about Robots
date: 2017-10-22
blurb: A conversation about AI helps me figure out where I stand
layout: post
---

J., M., T. and I have been having a discussion at work.
It started when M. forwarded
me [an article](https://deepmind.com/blog/alphago-zero-learning-scratch/)
about how a Google AI
(artificial intelligence) got really
good at playing Go...eventually beating all human players, and with a
complete lack of "domain knowledge" coming from Go experts.

The AI just bootstraps itself into brilliance. It continues playing
against itself and extends the state of the art further than any human
ever did.

My response was, "it makes me sad." M. wondered why I'd say that.
My argument was hard to articulate, and it took two days and follow-up
conversations with different people.

I pointed out that in the past, more of the educated population knew how
to make a good drawing. After the rise of photography, and now that we have
images all around us all the time, we don't see the need to draw...therefore,
most of us don't know how to do it.

But being able to draw well is an activity that extends the sensitivity of
your mind...it increases your powers of concentration...it really gives you
something besides the functional result of the activity. It's also connected
with the ability to simply *see* ever better. To observe keenly is not something
I knew how to do when I was younger. I seem to slowly get better at it.
Lately, I credit Zen meditation and well, learning to draw as helping me
in this space.

So...to recap...we built a fantastic tool -- photography. And we, in
aggregate, did less deep excavation into ourselves to bring forth something.
There was simply no need.

I pointed to music as well. There are far too few musicians for pleasure in
this world. As a teenager, I thought of Germany as a kind of "home" for western
music. But only a handful of people play. It's a shame, I think.

M. has a fantastic motivation for playing Go, and his approach
means the activity will remain enjoyable through many years, no matter what
violence computers do to the game. "I'm interested in interacting with another
mind through the medium of these simple rules...the rules don't really limit
our activity...they act instead as scaffolding that allows us to extend
ourselves further. If I were to play against a computer it wouldn't have the
same richness for me."

Over coffee later, T. pointed out that eventually M. may have a hard time
finding a human opponent because an AI will do it's best to mimic humans.
"You can mimic arbitrarily well, and I'm sure you can eventually exceed the
capacity of a human to tell the difference," he said.

Again, sadness, for me.

At this point I come up against the argument that well, we always build tools and
move on. We simply climb the abstraction ladder and exercise our creativity at a
new "higher" level. This argument often convinces me, but now I'm unable to
get behind the notion of "higher" and "lower" levels. Having felt the joy of
sinking into a simple chair after two days of walking, I eventually learned
that the simple pleasures are best. A world in which we operate ever
more abstractly and powerfully, with systems of automation
hard behind is not an exciting world for me.

I no longer trust abstraction further than I can throw it. With every increase
in power you throw out the particular in favor of the uniform. Because it seems
to work, you keep doing that. Before long you are manipulating an environment
you risk understanding in a cartoonish way.

There is a
[critique of the powerful](https://www.theguardian.com/commentisfree/2014/mar/26/caring-curse-working-class-austerity-solidarity-scourge)
that strikes a chord with me: they use
money to save themselves the effort of understanding people with less of it.
Those without so much money are forced to get inside the heads of their "betters,"
and really understand them more. There may be truth to the notion that we
don't have violent revolutions because the act of understanding another creates
goodwill towards them. The many work hard to understand the few, and find that
they can live with the predations inflicted upon them. To me, this is both a sad
and beautiful expression of the human condition...of our folly.

Coming back to my dubious attitude towards abstraction and the tech that
we use to foster these ladder climbs, I'm also just plain exasperated with the way
our technology is incredibly fussy. How it breaks when
you look away from it for a day or a month. It always seems to follow the same
arc...and each new iteration which promises to fix the problems of the old
one meet the same fate as the old one. So I have a bias towards not climbing
these ladders of complexity. Or at least asking a querulous "why?" before
beginning the ascent.

I should make a distinction here between tools and pleasure. Now, it's a false
distinction. Since I want to find pleasure in my work, I want to find pleasure
in my tools; to consider them well-made, and exercise my judgment to get
ever-closer to a craftsmanlike ideal. But let's make it anyway and declare
that when it comes to tools that increase our Productivity...when it's clear
that higher Productivity is the higher goal in a given context, then why,
I should welcome any and all intelligence that finds it's way into the tools.

It's when we start talking about pleasure that I think I'm on stronger ground
to object to excessive automation. I think the pleasure is in the work.
The climbing of a mountain is bound up in the work of sweating your way up
the hill...if that part was automated the climb would be meaningless.

I argue it's the same with art and music.

J. asked today: "does it matter *how* it was produced? If you had a selection
of beautiful antiques, and some were genuine, and the others had backstories
that were embellished, why should your pleasure in these objects be
diminished if the provenance is not 100% genuine?"

My thought there was that I would first insist that the *how* does matter.
And my next thought surprised me: I would wonder what was I doing in this
whole space at all?

That is...if you occupy a space where you no longer control the how of the
activity or object, then you are forced to look at where you are standing.
It may then feel better to let the whole thing go and do something else.

The game is up.

It's time to move on.

---

We've been long engaged in a wonderful game. Our intellects carried us to
the moon and soon enough to other planets. We can land robots on comets.
We juggle outrageous complexity in many domains. What a story! What a moral
victory, and this across generations.

![Some of my super-basic drawing](images/articles/philosophy/drawing.jpg)

But now our helpful tools dominate our world. They've escaped our grasp, and
they remake the world in ways we wouldn't have chosen.

In the early 1990s, texting with my girlfriend on some university talk server
from Texas to California, I thought the internet was the beginning of a
bright future. Now I see that the more we share information, the less
independence of thought we really feel in our lives. Our heads are full of
the thoughts of other people.

Did we really add anything new to the world, or did we just make it more
crowded? Did we just add more signs, more mailboxes to check?

---

We do have a funny relationship with these ever-more-brilliant AIs. When wearing
one kind of hat, we marvel at them. With another we fear them.

My default hat these days is a kind of weary resignation. "So this is what
we are doing now? M'okay."

I would like to understand the world by narrowing it down to the simplest
elements...those as close to me as possible...those among which I have some
hope of forging an understanding of what this maddening and glorious existence
really is.

From this perspective what the AIs do seems like pointless arcs of computation.

In these paragraphs I do risk falling off the "grumpy old man" deep end.
Let me introduce something new to stay on the wall a little longer!

---

J. and I today after our traditional Friday beer...I've managed to answer his
question about the *how* and why it matters in the affirmative, and I don't even
feel bad about it. This is usually where I get dismissed as a Luddite (which I
probably am, but I don't want to be dismissed...I always want to keep talking!).

But J. didn't do this. He said "actually, that position may be better because
it selects for more information. If we made an AI that writes a fiction story,
then no matter how good the story is, it will be composed of combinatoric 
permutations on existing themes. To make an AI is itself an expression of
regularity, of *reproducability*. So if you sit at the feet of this AI and
listen to it's story, you are consuming less real information than if you
listened to a story told by a human, who because of her organic fallibility
will never perfectly execute every twist in the tale. Her imperfect siting
in a shared context implies errors, whether adorable or annoying. Those
errors are *information*."

Whew, J. saves the day! He rescued me from a "just *because!*" position.
Indeed...I want to learn. We want to learn. We want to engage with the world
and we want good food, not junk. You are more likely to get good food in
a diverse environment. This means an environment full of what we think of as
error. Good food means information-rich content with which to engage.

---

Now, clever readers will immediately begin thinking how to incorporate this
insight into AIs that they are building. In fact, I'm sure this is all old
ground, covered in some 1970s books gathering dust in an MIT lab. But I
don't apologize for re-inventing the wheel...I'm having fun here. You are
either having fun with me or this whole line is a rehash of your past.

Again, we see the joy of rich information. Old to you, new to me. This whole
thread is my way of gripping the reality of the world at this moment.

W00t! Laterz!

